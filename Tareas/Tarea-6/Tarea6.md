# Titulo
Desarrollo y Evaluación de un Producto Mínimo Viable basado en Inteligencia Artificial para la Generación Eficiente de Identificación de Casos de Pruebas en Equipos Ágiles en la Empresa Patito SRL en la gestión 2025

# Índice

- [Introducción](#introducción)
- [1. Antecedentes del problema](#1-antecedentes-del-problema)
- [Fundamentos del enfoque, diseño y tipo de investigación](#fundamentos-del-enfoque-diseño-y-tipo-de-investigación)
- [Fundamentos del planteamiento del problema](#fundamentos-del-planteamiento-del-problema)
- [2. Formulación del problema](#2-formulación-del-problema)
  - [2.1. Objeto de estudio](#21-objeto-de-estudio)
  - [2.2. Campo de acción](#22-campo-de-acción)
- [3. Objetivos de la investigacion](#3-objetivos-de-la-investigacion)
  - [3.1. Objetivo General](#31-objetivo-general)
  - [3.2. Objetivos Específicos](#32-objetivos-específicos)
- [4. Justificación](#4-justificación)
  - [4.1. Justificación Teórica](#41-justificación-teórica)
  - [4.2. Justificación Práctica](#42-justificación-práctica)
  - [4.3. Justificación Económica](#43-justificación-económica)
  - [4.4. Justificación Metodológica](#44-justificación-metodológica)
  - [4.5. Justificación Personal](#45-justificación-personal)
- [5. Formulación de la construcción teórica. Hipótesis para Defender](#5-formulación-de-la-construcción-teórica-hipótesis-para-defender)
  - [5.1 Identificación de las variables](#51-identificación-de-las-variables)
- [Capítulo 1. Referentes teóricos](#capítulo-1-referentes-teóricos)
  - [Referencia a núcleos teóricos a desarrollar en la investigación](#referencia-a-núcleos-teóricos-a-desarrollar-en-la-investigación)
    - [1.1.1. Objeto de estudio](#111-objeto-de-estudio)
    - [1.1.2. Campo de acción](#112-campo-de-acción)
    - [1.1.3. Cómo del objetivo general](#113-cómo-del-objetivo-general)
  - [1.2. Índice Detallado para el Desarrollo del Marco Teórico](#12-índice-detallado-para-el-desarrollo-del-marco-teórico)
- [Capítulo 2. Diseño metodológico](#capítulo-2-diseño-metodológico)
  - [2.1. Tipo, Enfoque y Alcance de la Investigación](#21-tipo-enfoque-y-alcance-de-la-investigación)
  - [2.2. Delimitación de la Investigación](#22-delimitación-de-la-investigación)
  - [2.3. Definición Conceptual de las Variables](#23-definición-conceptual-de-las-variables)
  - [2.4. Definición Operacional de las Variables](#24-definición-operacional-de-las-variables)
  - [2.5. Métodos de Investigación](#25-métodos-de-investigación)
  - [2.6. Técnicas de Recolección de Datos de la Investigación](#26-técnicas-de-recolección-de-datos-de-la-investigación)
  - [2.7. Instrumentos de Investigación](#27-instrumentos-de-investigación)
- [Referencias Bibliográficas](#referencias-bibliográficas)
- [Bibliografía](#bibliografía)
- [Anexos](#anexos)

---

# Introducción

En la era digital actual, la agilidad y la innovación son factores críticos para mantener la competitividad en el desarrollo de software. Con la creciente complejidad de las aplicaciones y la necesidad de lanzamientos rápidos, la generación y validación de casos de prueba se ha vuelto esencial para garantizar la calidad del producto final. Según el artículo "The Future of Software Testing: AI-Powered Test Case Generation and Validation" (Baqar & Khanda, 2024), la integración de la inteligencia artificial (IA) en el proceso de testing permite ampliar la cobertura de pruebas y reducir significativamente los tiempos de validación, ofreciendo una ventaja competitiva en entornos ágiles.

Los equipos ágiles enfrentan el desafío de generar manualmente casos de prueba que se ajusten a ciclos de desarrollo cortos y en constante cambio. Esta práctica tradicional puede provocar retrasos, errores y una cobertura insuficiente, afectando la calidad del software. Estudios recientes indican que la automatización impulsada por IA no solo optimiza estos procesos, sino que también reduce la incidencia de errores humanos, mejorando la precisión en la detección de defectos (Ramadan, Yasin, & Pektas, 2024).

En respuesta a esta problemática, el proyecto **"Desarrollo y Evaluación de un Producto Mínimo Viable basado en Inteligencia Artificial para la Generación Eficiente de Identificación de Casos de Pruebas en Equipos Ágiles en la Empresa Patito SRL en la gestión 2025"** se plantea como una solución innovadora. La propuesta se orienta a desarrollar y evaluar experimentalmente un producto mínimo viable basado en IA para la generación y validación de casos de prueba, permitiendo a los equipos ágiles reducir la carga manual, minimizar costos y mejorar la cobertura y calidad de las pruebas. Esta iniciativa se alinea con las tendencias actuales en la industria, donde se observa una adopción creciente de soluciones basadas en IA que optimizan los procesos de aseguramiento de la calidad.

El tema de investigación **"Desarrollo y Evaluación de un Producto Mínimo Viable basado en Inteligencia Artificial para la Generación Eficiente de Identificación de Casos de Pruebas en Equipos Ágiles en la Empresa Patito SRL en la gestión 2025"** se alinea con la **línea de investigación en Ingeniería de Software**, enmarcándose en el **eje temático de Validación, Mantenimiento y Evolución del Software**. Esta propuesta se orienta hacia la construcción y evaluación experimental de un producto mínimo viable para entornos de desarrollo ágil, haciendo uso de técnicas avanzadas de IA para automatizar la generación de casos de prueba, lo cual contribuye a mejorar la calidad y eficiencia del software.

El objetivo principal es desarrollar un producto mínimo viable basado en IA que se integre en el flujo de trabajo ágil de la Empresa Patito SRL, facilitando la Generación Eficiente de Identificación de Casos de Pruebas. Este enfoque experimental no solo busca demostrar la mejora en los tiempos de desarrollo y entrega, sino también verificar la adaptabilidad de la solución frente a los cambios continuos en los requisitos. La investigación se fundamenta en la construcción y evaluación de un producto concreto que permita probar empíricamente cómo la Inteligencia Artificial puede transformar el ciclo de vida del software, elevando la calidad y la productividad de manera sostenible.

# 1. Antecedentes del problema

La inteligencia artificial (IA) está revolucionando múltiples áreas del desarrollo de software, especialmente en el **aseguramiento de la calidad.** Uno de los aspectos donde más impacto ha tenido es en la generación automática de casos de prueba, una actividad crítica para garantizar la robustez de los sistemas desarrollados. En paralelo, las metodologías ágiles, ampliamente adoptadas por las empresas modernas, exigen rapidez, adaptabilidad y eficiencia en todos los procesos. La integración de IA en entornos ágiles ofrece una oportunidad única para automatizar y mejorar la calidad de las pruebas de software. Este bloque de antecedentes revisa estudios relevantes sobre cómo estas tecnologías pueden aplicarse de manera efectiva en contextos similares al de la empresa Patito S.R.L.

En su análisis sobre pruebas de software impulsadas por IA, Aufiero Informática (2023) señala que "las herramientas basadas en inteligencia artificial permiten generar casos de prueba a partir de modelos, datos históricos o incluso mediante técnicas de aprendizaje automático". Este enfoque permite una mayor cobertura en menos tiempo, **reduciendo el esfuerzo manual.** Este tipo de automatización podría ser adoptado por Patito S.R.L. para complementar los ciclos de prueba en sus equipos ágiles, permitiendo una validación más rápida de nuevas funcionalidades.

Por otro lado, Certiprof (2023) destaca que "la convergencia entre la inteligencia artificial y las metodologías ágiles permite automatizar tareas repetitivas, analizar grandes volúmenes de datos y mejorar la toma de decisiones en tiempo real". Esto sugiere que, más allá de la automatización de pruebas, la IA también puede facilitar la planificación y gestión del trabajo en equipos ágiles. En el contexto de Patito S.R.L., donde se desarrollan soluciones de software bajo marcos ágiles, este tipo de integración puede mejorar la eficiencia operativa y reducir errores en los entregables.

El estudio de Khan y Ali (2023) sobre el framework *TestLab* plantea una propuesta integral para automatizar pruebas utilizando IA. Los autores afirman que "la combinación de generación, ejecución y análisis de pruebas en un solo entorno inteligente mejora la retroalimentación continua y la calidad del software". **Esta propuesta resulta aplicable a Patito S.R.L.,** especialmente si se busca escalar las pruebas automatizadas en múltiples proyectos sin perder trazabilidad ni control sobre los resultados.

Finalmente, desde una perspectiva práctica, Guru99 (2024) identifica herramientas como Testim y Applitools que "utilizan inteligencia artificial para identificar patrones en el código y generar pruebas adaptativas que se ajustan a los cambios frecuentes en los entornos ágiles". Esto es especialmente útil en organizaciones como Patito S.R.L., que trabajan con entregas incrementales y cambios constantes. Estas herramientas pueden integrarse fácilmente en el pipeline de integración continua para facilitar validaciones automáticas más inteligentes.

En conjunto, las fuentes revisadas coinciden en que la integración de inteligencia artificial en el proceso de pruebas de software no solo es técnicamente viable, sino altamente beneficiosa, especialmente en entornos ágiles. El desarrollo y evaluación de un producto mínimo viable basado en estas tecnologías en Patito S.R.L. podría representar una mejora significativa en la calidad del software, la velocidad de entrega y la eficiencia del equipo. Estas evidencias justifican la necesidad de construir, implementar y evaluar experimentalmente un producto mínimo viable basado en IA que se adapte a las dinámicas ágiles de la organización.

# Fundamentos del enfoque, diseño y tipo de investigación

El proyecto aborda la necesidad crítica de optimizar la generación de casos de prueba para mejorar la calidad y eficiencia del software desarrollado en contextos ágiles. El objetivo principal de esta investigación es desarrollar y evaluar un producto mínimo viable basado en Inteligencia Artificial para la Generación Eficiente de Identificación de Casos de Pruebas, que permita demostrar empíricamente los beneficios de esta tecnología en un contexto empresarial específico: la empresa Patito SRL en Santa Cruz durante la gestión 2025.

El enfoque metodológico adoptado es cuantitativo, bajo el paradigma positivista. Esta elección se fundamenta en la necesidad de medir objetivamente los beneficios de la aplicación de IA, utilizando métricas claras como tiempos de generación, precisión de los casos generados y cobertura de pruebas. Este enfoque permitirá validar empíricamente la eficacia y eficiencia de la tecnología aplicada, proporcionando evidencia objetiva que respalde la adopción y expansión de soluciones avanzadas para resolver problemas específicos y recurrentes en la industria del software.

El diseño metodológico del proyecto es experimental con un enfoque cuasi-experimental, incluyendo un grupo de control y un grupo experimental para comparar la eficiencia y calidad entre los procesos manuales tradicionales y el producto mínimo viable basado en IA. Se contempla inicialmente la recolección de datos a través de encuestas y entrevistas para evaluar la situación actual, seguida por el desarrollo e implementación del producto mínimo viable basado en técnicas de Machine Learning y procesamiento de lenguaje natural. Finalmente, se realizarán análisis estadísticos para evaluar los resultados obtenidos y comprobar la hipótesis planteada.

Esta metodología permitirá a la empresa Patito SRL evidenciar con claridad el impacto real de un producto mínimo viable basado en Inteligencia Artificial para la Generación Eficiente de Identificación de Casos de Pruebas, facilitando decisiones estratégicas futuras basadas en evidencia empírica sobre la adopción y escalamiento de la solución.

# Fundamentos del planteamiento del problema

El desarrollo de software ágil presenta múltiples retos relacionados con la rapidez de entrega, precisión de los procesos y capacidad de adaptación a requisitos en constante cambio. En la empresa Patito SRL, uno de los principales desafíos identificados es la generación manual de casos de prueba, un proceso que consume recursos, es propenso a errores y limita la cobertura necesaria para garantizar la calidad del producto final.

A partir de un análisis exploratorio respaldado por una matriz FODA (ver Anexo 1), se identificaron problemáticas clave que afectan directamente la eficiencia del equipo y la calidad del software:

- Dependencia excesiva del esfuerzo humano en la generación manual de casos de prueba.
- Baja eficiencia operativa debido a la falta de automatización.
- Carencia de personal especializado en técnicas avanzadas de IA.
- Resistencia interna al cambio hacia metodologías automatizadas.
- Riesgo de obsolescencia tecnológica.
- Alta competencia regional en soluciones tecnológicas.
- Cobertura insuficiente y errores frecuentes en pruebas manuales.
- Retrasos en la entrega de funcionalidades por cuellos de botella en la validación.

Frente a estas debilidades, también se identificaron oportunidades estratégicas:

- Adopción creciente de herramientas de Inteligencia Artificial en el sector.
- Disponibilidad de tecnologías compatibles con metodologías ágiles.
- Acceso a bibliotecas y plataformas de automatización.
- Iniciativas organizacionales por mejorar la calidad del producto.
- Posibilidad de posicionamiento competitivo a través de la innovación.

Si bien el enfoque inicial de la investigación contempla un diagnóstico cuantitativo de la situación actual, dicho análisis no es un fin en sí mismo, sino un medio para fundamentar una propuesta viable que permita la incorporación de soluciones basadas en IA. De este modo, la etapa de medición se proyecta como una base sólida para sustentar el diseño y justificación de una propuesta adaptada al contexto ágil de Patito SRL.

La situación problemática se enmarca en la contradicción entre el proceso actual, limitado y manual, y las posibilidades que ofrecen las tecnologías emergentes para transformar dicho proceso en uno automatizado, más eficiente, adaptable y alineado con estándares modernos de calidad. Esta brecha revela una necesidad urgente de propuesta tecnológica orientada a la mejora continua y sostenibilidad de los procesos de prueba en el contexto de desarrollo ágil.

# 2. Formulación del problema

¿Cómo el desarrollo y evaluación de un producto mínimo viable basado en Inteligencia Artificial puede contribuir a la Generación Eficiente de Identificación de Casos de Pruebas en los Equipos Ágiles de la empresa Patito SRL en Santa Cruz, Bolivia, durante la gestión 2025?

## 2.1. Objeto de estudio

El desarrollo y evaluación de un producto mínimo viable para la Generación Eficiente de Identificación de Casos de Pruebas en Equipos Ágiles de la empresa Patito SRL en Santa Cruz, Bolivia.

## 2.2. Campo de acción

La implementación experimental y validación del producto mínimo viable basado en Inteligencia Artificial para la Generación Eficiente de Identificación de Casos de Pruebas en los Equipos Ágiles de la empresa Patito SRL en Santa Cruz, Bolivia, durante la gestión 2025.

Su **alcance** se concreta en la **mejora del proceso de testing de software** en la empresa Patito SRL, específicamente enfocado en la **Generación Eficiente de Identificación de Casos de Pruebas** mediante el desarrollo y la evaluación experimental del producto mínimo viable basado en Inteligencia Artificial dentro de sus Equipos Ágiles, contextualizado en Santa Cruz, Bolivia, durante la gestión 2025.

# 3. Objetivos de la investigacion

## 3.1. Objetivo General

Desarrollar un producto mínimo viable basado en Inteligencia Artificial para la Generación Eficiente de Identificación de Casos de Pruebas en Equipos Ágiles, que demuestre la mejora significativa en la eficiencia del proceso de validación de software en la empresa Patito SRL durante la gestión 2025.

## 3.2. Objetivos Específicos

1. Diagnosticar el estado actual del proceso de Generación de Identificación de Casos de Pruebas en los Equipos Ágiles de la empresa Patito SRL, identificando las principales problemáticas y oportunidades de mejora.

2. Diseñar un producto mínimo viable para la Generación Eficiente de Identificación de Casos de Pruebas basado en técnicas de Inteligencia Artificial que atienda las necesidades específicas de los proyectos ágiles de la empresa.

3. Implementar el producto mínimo viable diseñado, permitiendo la Generación Eficiente de Identificación de Casos de Pruebas en un entorno controlado.

4. Evaluar experimentalmente el producto mínimo viable implementado en comparación con los métodos tradicionales, mediante métricas cuantitativas como tiempo de generación, cobertura y precisión.

5. Establecer un plan de escalamiento para el producto mínimo viable basado en los resultados obtenidos durante la fase experimental en los Equipos Ágiles de la empresa Patito SRL.

# 4. Justificación

## 4.1. Justificación Teórica

Este estudio aporta al campo teórico de la ingeniería de software al integrar conceptos avanzados de Inteligencia Artificial, particularmente el aprendizaje automático y el procesamiento de lenguaje natural, en el proceso de generación de casos de prueba. Dichas técnicas han sido discutidas por autores como Baqar y Khanda (2024), quienes destacan su potencial para transformar los procesos de aseguramiento de la calidad del software. La propuesta permite reforzar los marcos conceptuales existentes al adaptar modelos de automatización al contexto ágil, aportando así nuevas perspectivas para futuras investigaciones.

Además, autores como Harman y Clark (2004) han explorado la aplicación de técnicas evolutivas en la generación automática de pruebas, contribuyendo con fundamentos sobre cómo los algoritmos inteligentes pueden mejorar la calidad del software desde etapas tempranas. Por otro lado, Weyuker (1998) resalta la complejidad inherente en el diseño de casos de prueba efectivos, subrayando la necesidad de enfoques automatizados. Finalmente, Li, Harman y Hierons (2007) evidencian cómo los métodos inteligentes permiten una mayor cobertura y eficiencia en procesos de prueba, fortaleciendo la base conceptual de esta investigación.

## 4.2. Justificación Práctica

La investigación brinda una solución concreta a una necesidad operativa de la empresa Patito SRL a través del desarrollo de un producto mínimo viable para la Generación Eficiente de Identificación de Casos de Pruebas. Este producto permitirá reducir errores, acelerar los tiempos de desarrollo y aumentar la cobertura de validación. Al construir y evaluar este producto basado en IA, se espera demostrar empíricamente la mejora significativa en la calidad del producto entregado y la liberación de recursos humanos para tareas de mayor valor estratégico. Este enfoque pragmático, centrado en un producto mínimo viable, permite validar rápidamente la propuesta de valor antes de invertir en una solución a gran escala, facilitando la adopción gradual y basada en evidencia de innovaciones tecnológicas en la organización.

## 4.3. Justificación Económica

Desde el punto de vista económico, el desarrollo de un producto mínimo viable basado en IA representa una inversión inicial acotada que permitirá a Patito SRL evaluar los beneficios potenciales antes de comprometer mayores recursos. Este enfoque de validación empírica permite cuantificar con precisión la reducción de costos asociados a reprocesos, fallos en producción y retrasos en las entregas. Si los resultados del producto mínimo viable son positivos, se podrá justificar una inversión mayor en el escalamiento de la solución, con un claro entendimiento del retorno de inversión esperado y reduciendo significativamente el riesgo empresarial. Esta metodología ágil de desarrollo e implementación se alinea con las mejores prácticas de gestión de innovación tecnológica en la industria actual.

## 4.4. Justificación Metodológica

La investigación se justifica metodológicamente al proponer un enfoque experimental basado en la construcción y evaluación de un producto mínimo viable para la Generación Eficiente de Identificación de Casos de Pruebas. Se establecerán indicadores de rendimiento como tiempo promedio de generación, número de errores detectados y cobertura lograda, lo que permitirá comparar objetivamente los resultados obtenidos respecto a los métodos manuales tradicionales. Este enfoque, fundamentado en la metodología científica, permite validar la hipótesis mediante evidencia empírica directa, en lugar de proyecciones teóricas. Para recolectar datos cuantificables, se utilizará la experimentación controlada como instrumento principal, garantizando la coherencia con el enfoque metodológico cuantitativo declarado. Esta metodología de validación empírica a través de un producto mínimo viable constituye un aporte significativo a las prácticas de investigación en el campo de la ingeniería de software.

## 4.5. Justificación Personal

La motivación personal para realizar esta investigación surge del interés profundo del autor por aplicar soluciones innovadoras y tecnológicas a problemas reales en entornos empresariales. Como amante de la calidad del software y con varios años de experiencia profesional en este campo, el autor ha sido testigo de cómo han evolucionado las metodologías y herramientas de aseguramiento de la calidad. Esta investigación representa no solo un compromiso con la mejora continua, sino también una oportunidad para combinar esa experiencia acumulada con tecnologías emergentes como la Inteligencia Artificial, generando un aporte significativo tanto para la organización como para el avance del conocimiento profesional en el área.

# 5. Formulación de la construcción teórica. Hipótesis para Defender

Si se desarrolla un producto mínimo viable basado en Inteligencia Artificial para la Generación Eficiente de Identificación de Casos de Pruebas en Equipos Ágiles, entonces se demostrará una mejora significativa en la eficiencia del proceso de validación de software en la empresa Patito SRL durante la gestión 2025.

## 5.1 Identificación de las variables

**Variable independiente:** Producto mínimo viable basado en Inteligencia Artificial para la Generación Eficiente de Identificación de Casos de Pruebas.

**Variable dependiente:** Eficiencia en el proceso de validación de software en equipos ágiles.

# Capítulo 1. Referentes teóricos

## Referencia a núcleos teóricos a desarrollar en la investigación

- Inteligencia Artificial: aprendizaje automático, NLP.
- Automatización en testing de software.
- Enfoques ágiles de desarrollo (Scrum, XP).
- Calidad del software.

### 1.1.1. Objeto de estudio

El **desarrollo y evaluación de un producto mínimo viable (MVP) basado en Inteligencia Artificial (IA)**, enfocado en la generación eficiente de identificación de casos de prueba, constituye el núcleo central de esta investigación. Este objeto se fundamenta en la integración de varios pilares teóricos clave, cuyo objetivo final es la mejora tangible del aseguramiento de la calidad del software en entornos ágiles como el de Patito SRL.

Un pilar fundamental es la **Inteligencia Artificial**, específicamente las técnicas de aprendizaje automático (Machine Learning) y Procesamiento del Lenguaje Natural (NLP). Estas tecnologías, como señalan Baqar y Khanda (2024), son esenciales para analizar requisitos, comprender patrones en el código o especificaciones y generar automáticamente casos de prueba relevantes y efectivos, formando así la base tecnológica del MVP propuesto.

La **Automatización en el Testing de Software** es otro componente teórico crucial. El objetivo del MVP no es solo generar casos de prueba, sino hacerlo de manera eficiente, reduciendo la intervención manual. La teoría de la automatización subraya los beneficios en velocidad, consistencia y cobertura (Khan & Ali, 2023), aspectos que este MVP busca materializar en el proceso de identificación de casos de prueba.

El contexto de aplicación exige considerar los **Enfoques Ágiles de Desarrollo (Scrum, XP)**. El MVP no puede ser una entidad aislada; debe integrarse y aportar valor dentro de los ciclos iterativos y rápidos propios del agilismo en Patito SRL. La teoría ágil (Certiprof, 2023) guía cómo el MVP debe ser flexible, proporcionar feedback rápido y adaptarse a los cambios constantes inherentes a estos entornos.

Finalmente, la **Calidad del Software** actúa como el marco teórico que define el éxito del MVP. Más allá del desarrollo, la "evaluación" del objeto de estudio se guiará por métricas y conceptos de calidad (cobertura, detección de defectos, eficiencia). La teoría de la calidad proporciona los criterios y estándares contra los cuales se medirá la efectividad y el impacto del MVP implementado.

En síntesis, el objeto de estudio – el desarrollo y evaluación del MVP – es una empresa multidisciplinaria que converge la aplicación de IA, los principios de automatización de pruebas, la adaptación a metodologías ágiles y la medición rigurosa bajo los estándares de calidad del software. La interacción de estos pilares teóricos define la naturaleza y alcance de este proyecto de investigación.

### 1.1.2. Campo de acción

La **implementación y validación experimental del producto mínimo viable (MVP)** en los Equipos Ágiles de la empresa Patito SRL, como campo de acción específico de esta investigación, se sustenta directamente en los fundamentos teóricos establecidos en el objeto de estudio. Estos pilares —la **Inteligencia Artificial** (con aprendizaje automático y NLP), la **Automatización en Testing de Software**, los **Enfoques Ágiles de Desarrollo** y la **Calidad del Software**— aplicados dentro de este campo de acción, proporcionan el marco metodológico y conceptual necesario. Dicha integración garantiza que el desarrollo y la evaluación del MVP no solo aborden la generación eficiente de identificación de casos de prueba, sino que también se validen rigurosamente su efectividad y adaptabilidad en el entorno operativo real de Patito SRL durante la gestión 2025.

### 1.1.3. Cómo del objetivo general

La fundamentación teórica que sustenta **cómo** se alcanzará el objetivo general – el desarrollo y evaluación del producto mínimo viable (MVP) – se basa en la integración de los pilares teóricos clave identificados: **Inteligencia Artificial** (con énfasis en aprendizaje automático y NLP), **Automatización en Testing de Software**, **Enfoques Ágiles de Desarrollo** y **Calidad del Software**. Estos núcleos teóricos, que emanan directamente del objeto de estudio (el MVP) y el campo de acción (su implementación experimental en Patito SRL), proporcionan el marco conceptual y técnico necesario. Esta integración garantiza que el MVP no solo se desarrolle sobre bases sólidas, sino que también se evalúe empíricamente su capacidad para lograr la **Generación Eficiente de Identificación de Casos de Pruebas**, abordando así directamente el objetivo general de la investigación.

## 1.2. Índice Detallado para el Desarrollo del Marco Teórico

- **1.1. Fundamentos del Aseguramiento de la Calidad del Software**
  - 1.1.1. Evolución Histórica del Testing de Software
  - 1.1.2. Principios Fundamentales de la Calidad del Software (ISO/IEC 25010)
  - 1.1.3. El Proceso de Testing: Niveles, Tipos y Técnicas
    - 1.1.3.1. Pruebas Unitarias, de Integración, de Sistema y de Aceptación
    - 1.1.3.2. Pruebas Funcionales y No Funcionales
    - 1.1.3.3. Técnicas de Diseño de Casos de Prueba (Caja Negra, Caja Blanca, Experiencia)
  - 1.1.4. Desafíos del Testing Manual en Proyectos Modernos

- **1.2. Metodologías Ágiles de Desarrollo y su Impacto en el Testing**
  - 1.2.1. Principios y Valores del Manifiesto Ágil
  - 1.2.2. Frameworks Ágiles Comunes y su Aplicación en Patito SRL (si aplica)
    - 1.2.2.1. Scrum: Roles, Eventos y Artefactos
    - 1.2.2.2. Kanban: Flujo de Trabajo y Limitación del WIP
    - 1.2.2.3. Extreme Programming (XP): Prácticas Clave
  - 1.2.3. El Rol del Aseguramiento de Calidad (QA) en Equipos Ágiles
    - 1.2.3.1. Testing Continuo e Integración Continua (CI/CD)
    - 1.2.3.2. Automatización de Pruebas en Ciclos Cortos (Sprints)
    - 1.2.3.3. Colaboración entre Desarrollo, QA y Negocio (BDD/ATDD como opción)
  - 1.2.4. Retos Específicos del Testing en Contextos Ágiles (Velocidad, Cambios Frecuentes)

- **1.3. Inteligencia Artificial Aplicada al Testing de Software**
  - 1.3.1. Conceptos Fundamentales de Inteligencia Artificial Relevantes
    - 1.3.1.1. Aprendizaje Automático (Machine Learning): Supervisado, No Supervisado, Reforzado
    - 1.3.1.2. Procesamiento del Lenguaje Natural (NLP): Técnicas y Aplicaciones
    - 1.3.1.3. Algoritmos de Búsqueda y Optimización
  - 1.3.2. Aplicaciones de la IA en el Ciclo de Vida del Testing
    - 1.3.2.1. Análisis Inteligente de Requisitos y Especificaciones
    - 1.3.2.2. Generación Automática y Priorización de Casos de Prueba (Enfoque Principal)
    - 1.3.2.3. Optimización de Suites de Pruebas (Reducción de Redundancia)
    - 1.3.2.4. Detección Inteligente de Defectos y Análisis de Causa Raíz
    - 1.3.2.5. Pruebas Auto-adaptativas y Auto-reparadoras
  - 1.3.3. Técnicas Específicas de IA para la Generación/Identificación de Casos de Prueba
    - 1.3.3.1. Generación Basada en Modelos (MBTG) con IA
    - 1.3.3.2. Pruebas Basadas en Búsqueda (Search-Based Software Testing - SBST)
    - 1.3.3.3. NLP para la Generación desde Requisitos en Lenguaje Natural
    - 1.3.3.4. Aprendizaje por Refuerzo para Explorar Espacios de Prueba

- **1.4. Medición de la Eficiencia y Efectividad en el Testing Automatizado con IA**
  - 1.4.1. Métricas Tradicionales de Testing y su Adaptación
    - 1.4.1.1. Cobertura de Código (Statement, Branch, Path, MC/DC)
    - 1.4.1.2. Métricas de Defectos (Densidad, Tasa de Detección, Severidad)
    - 1.4.1.3. Tiempo y Esfuerzo de Testing
  - 1.4.2. Métricas Específicas para Evaluar Soluciones de Testing con IA
    - 1.4.2.1. Calidad y Relevancia de los Casos de Prueba Generados
    - 1.4.2.2. Tasa de Reducción de Esfuerzo Manual
    - 1.4.2.3. Capacidad de Detección de Regresiones (Mutation Testing)
    - 1.4.2.4. Adaptabilidad y Mantenibilidad de las Pruebas Generadas
  - 1.4.3. Evaluación del Retorno de Inversión (ROI) de la Automatización Inteligente

- **1.5. Estado del Arte: Herramientas y Casos de Estudio**
  - 1.5.1. Panorama Actual de Herramientas de Testing con IA
    - 1.5.1.1. Herramientas Comerciales (Ej: Testim, Applitools, Functionize, Mabl)
    - 1.5.1.2. Herramientas y Librerías Open Source (Ej: TestProject, bibliotecas ML/NLP)
    - 1.5.1.3. Frameworks de Investigación (Ej: TestLab citado)
  - 1.5.2. Estudios de Caso Relevantes
    - 1.5.2.1. Implementaciones Exitosas de IA en Testing Ágil
    - 1.5.2.2. Desafíos y Lecciones Aprendidas en la Adopción
- 1.5.3. Análisis Comparativo de Enfoques y Tecnologías

# Capítulo 2. Diseño metodológico

## 2.1. Tipo, Enfoque y Alcance de la Investigación

El tipo de investigación es **propositivo**, dado que busca desarrollar y evaluar una solución concreta (el MVP). El proyecto se desarrollará bajo un **enfoque cuantitativo**, desde la perspectiva del **paradigma positivista**. Esta elección se fundamenta en la necesidad de medir objetivamente los resultados y validar la hipótesis mediante datos numéricos. Se sustenta en la selección de un **diseño cuasi-experimental**, el cual es apropiado para evaluar el impacto de una intervención (el MVP) en un entorno real donde la asignación aleatoria de participantes a grupos puede no ser factible, permitiendo comparar grupos para determinar la efectividad de la solución propuesta.

Como diseño cuasi-experimental, la investigación implicará la comparación entre al menos dos grupos o condiciones: uno utilizando el método tradicional de identificación de casos de prueba (grupo de control o línea base) y otro utilizando el producto mínimo viable basado en IA (grupo experimental). La secuencia metodológica incluirá una fase inicial de **diagnóstico** para caracterizar la situación actual (apoyada por encuestas y análisis documental), seguida por el **desarrollo e implementación** controlada del MVP, y finalmente una fase de **evaluación comparativa** donde se recolectarán métricas cuantitativas (como tiempos, cobertura, precisión) para analizar estadísticamente las diferencias y verificar la hipótesis planteada sobre la mejora en la eficiencia.

Su **alcance** se concreta en la **mejora del proceso de testing de software** en la empresa Patito SRL, específicamente enfocado en la **Generación Eficiente de Identificación de Casos de Pruebas** mediante el desarrollo y la evaluación experimental del producto mínimo viable basado en Inteligencia Artificial dentro de sus Equipos Ágiles, contextualizado en Santa Cruz, Bolivia, durante la gestión 2025.

## 2.2. Delimitación de la Investigación

**Delimitación Temática:** La investigación se delimitará al **desarrollo y evaluación de un producto mínimo viable (MVP) basado en Inteligencia Artificial (IA)** para la **Generación Eficiente de Identificación de Casos de Pruebas en Equipos Ágiles**. Se fundamentará en teorías y conceptos clave de la Ingeniería de Software, la Inteligencia Artificial, el Testing Automatizado y las Metodologías Ágiles. Se tomarán en cuenta los enfoques de IA como el Aprendizaje Automático y el Procesamiento del Lenguaje Natural (Baqar & Khanda, 2024; Ramadan et al., 2024), las prácticas de automatización inteligente (Khan & Ali, 2023), la integración con flujos ágiles (Certiprof, 2023) y los principios de calidad del software para la evaluación. El estudio abarcará áreas del conocimiento como la ingeniería de software, el aseguramiento de la calidad (QA), la inteligencia artificial aplicada y la gestión de proyectos ágiles. Esta delimitación temática asegura que la investigación se centre en aplicar fundamentos teóricos robustos para crear y validar una solución tecnológica específica y medible.

**Delimitación Espacial:** La investigación se llevará a cabo en la **Empresa Patito SRL**, ubicada en la ciudad de **Santa Cruz de la Sierra, Bolivia**. El estudio se centrará específicamente en los **equipos de desarrollo que operan bajo metodologías ágiles** dentro de esta organización, proporcionando un contexto empresarial real para la implementación y validación experimental del MVP.

**Delimitación Temporal:** El trabajo de investigación, incluyendo el diagnóstico, diseño, implementación y evaluación experimental del MVP, se realizará durante la **gestión 2025**. La evaluación de la eficiencia y la demostración de la mejora se contextualizarán dentro de este período. El plan de escalamiento propuesto (Objetivo Específico 5) abordará la sostenibilidad y vigencia futura de la solución más allá de este marco temporal inicial.

## 2.3. Definición Conceptual de las Variables

El **"Producto mínimo viable basado en Inteligencia Artificial (MVP con IA)"** para la Generación Eficiente de Identificación de Casos de Pruebas se define conceptualmente como: **una versión inicial y funcional del sistema propuesto que implementa las características centrales necesarias para automatizar la identificación de casos de prueba utilizando técnicas de IA**, como el aprendizaje automático (Machine Learning) y el procesamiento del lenguaje natural (NLP). Siguiendo los principios ágiles y la necesidad de validación temprana (Certiprof, 2023), este MVP se enfoca en entregar el valor fundamental de la generación automatizada y permitir la evaluación experimental de su impacto. Según Baqar y Khanda (2024) y Ramadan et al. (2024), tales sistemas basados en IA son clave para transformar los procesos de testing. Conceptualmente, este MVP representa la **variable independiente** cuya implementación y evaluación constituyen el núcleo de la investigación.

La **"Eficiencia en el proceso de validación de software"**, en el contexto específico de la identificación de casos de prueba, se define conceptualmente como: la **medida en que los recursos (principalmente tiempo y esfuerzo humano) se utilizan de manera óptima para producir un conjunto efectivo de casos de prueba identificados, maximizando la calidad del resultado (cobertura, relevancia) con el mínimo input**. Se caracteriza por indicadores clave como la **reducción del tiempo** necesario para la tarea, el **aumento de la cobertura** de los requisitos o funcionalidades por los casos identificados, y la **mejora en la calidad o precisión de los casos generados** que potencialmente impacta la tasa de detección de errores downstream. Autores como Harman y Clark (2004) y Li et al. (2007) han trabajado en métricas para evaluar la generación de datos de prueba, fundamentos aplicables aquí. La mejora en la eficiencia, como variable dependiente, se busca demostrar comparando el desempeño del MVP con IA frente a los métodos tradicionales (Aufiero Informática, 2023).

## 2.4. Definición Operacional de las Variables

El **"Producto mínimo viable basado en Inteligencia Artificial (MVP con IA)"** (Variable Independiente) se define operativamente como el **sistema de software específico desarrollado e implementado** dentro de Patito SRL durante la gestión 2025. Este sistema utilizará algoritmos de IA (ML/NLP) para procesar entradas definidas (ej. requisitos) y producir salidas medibles (listas de casos de prueba identificados). Su presencia y funcionamiento según las especificaciones del diseño serán su manifestación operativa.

La **"Eficiencia en el proceso de validación de software"** (Variable Dependiente), enfocada en la identificación de casos de prueba, se define operativamente mediante la **medición y comparación de indicadores clave** recolectados durante la experimentación (Objetivo Específico 4). Estos indicadores se medirán tanto para el grupo experimental (usando el MVP) como para el grupo de control (método tradicional).

A continuación, se presenta el cuadro de operacionalización detallado:

**Cuadro 1. Operacionalización de las variables**

| VARIABLE                                                                    | DIMENSIONES                                    | INDICADORES                                                                                                                 | INSTRUMENTO / FUENTE DE DATOS (Ejemplos)                                     |
| :-------------------------------------------------------------------------- | :--------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------- |
| **1. Producto mínimo viable basado en IA (Variable Independiente)**           | 1.1. Funcionalidad Implementada                | 1.1.1. Capacidad de generar lista de casos de prueba a partir de input especificado (requisitos, código fuente, etc.)         | Verificación funcional del MVP desarrollado                                  |
|                                                                             | 1.2. Componentes de IA Utilizados              | 1.2.1. Algoritmos de ML/NLP específicos integrados y operativos según diseño.                                                 | Revisión de código fuente, Logs del sistema                                  |
|                                                                             | 1.3. Disponibilidad Operativa                  | 1.3.1. MVP desplegado y accesible para su uso en el entorno de pruebas controlado de Patito SRL.                              | Verificación de despliegue/infraestructura                                   |
| **2. Eficiencia en el proceso de validación de software (Variable Dependiente)** | 2.1. Tiempo/Esfuerzo Requerido                | 2.1.1. Tiempo promedio (ej. horas-hombre) para identificar casos de prueba por unidad de trabajo (historia de usuario, etc.). | Registros de tiempo, Cronometraje directo, Estimaciones (si aplica)        |
|                                                                             | 2.2. Cobertura Alcanzada                       | 2.2.1. Porcentaje de requisitos funcionales/criterios de aceptación cubiertos por los casos de prueba identificados.         | Matriz de trazabilidad, Herramientas de análisis de cobertura (si aplica) |
|                                                                             | 2.3. Calidad/Precisión de Casos Identificados | 2.3.1. Número o porcentaje de casos de prueba relevantes generados (evaluados por expertos QA).                             | Rúbrica de evaluación experta, Revisión por pares                          |
|                                                                             |                                                | 2.3.2. (Opcional/Indirecto) Tasa de detección de defectos usando los casos generados en fases posteriores.                   | Sistema de seguimiento de defectos (Bug Tracking System)                     |

**Fuente:** Elaboración propia, 2024 (adaptado del marco conceptual y objetivos).

## 2.5. Métodos de Investigación

Los métodos de obtención del conocimiento que serán aplicados en esta investigación se categorizan en métodos del nivel teórico y métodos del nivel empírico, alineados con el enfoque cuantitativo y el diseño cuasi-experimental del estudio.

### 2.5.1. Métodos del Nivel Teórico

**Método Histórico-Lógico**: Permitirá obtener una comprensión integral del proceso de validación de software y la evolución de técnicas de generación de casos de prueba, estableciendo una línea temporal desde las metodologías manuales tradicionales hasta los enfoques automatizados actuales basados en IA. Este método facilitará entender cómo han evolucionado las prácticas de testing en entornos ágiles y cómo la inteligencia artificial ha transformado este campo.

**Método Inductivo-Deductivo**: Se utilizará para establecer relaciones entre conceptos teóricos (calidad del software, inteligencia artificial, metodologías ágiles) y datos empíricos obtenidos durante la experimentación. Este método permitirá inferir conclusiones sobre la aplicabilidad general del MVP basado en los resultados específicos obtenidos en Patito SRL, y deducir estrategias específicas de implementación a partir de marcos teóricos generales sobre testing con IA.

**Método de Análisis-Síntesis**: Será aplicado para descomponer el proceso de generación de casos de prueba en sus componentes fundamentales (interpretación de requisitos, identificación de escenarios críticos, formulación de condiciones de prueba, etc.), analizando cada uno individualmente y luego reintegrándolos en una solución automatizada coherente implementada en el MVP. Este método apoyará tanto la fase de diagnóstico como la de diseño del producto.

**Método Hipotético-Deductivo**: Permitirá poner a prueba la hipótesis planteada mediante la observación sistemática de los resultados del MVP comparados con los métodos tradicionales. A partir de la hipótesis general sobre la mejora en la eficiencia, se deducirán predicciones específicas y verificables que serán sometidas a validación experimental.

### 2.5.2. Métodos del Nivel Empírico

En coherencia con el enfoque cuantitativo y el diseño cuasi-experimental declarado, se aplicarán los siguientes métodos empíricos para la obtención de datos:

**Observación Sistemática**: Se implementará para desarrollar una percepción objetiva del proceso actual de identificación de casos de prueba en los equipos ágiles de Patito SRL. Esta observación seguirá protocolos estructurados que permitan cuantificar aspectos como tiempos, esfuerzo, precisión y cobertura, proporcionando una línea base para comparar con los resultados del MVP.

**Experimentación Controlada**: Constituirá el núcleo metodológico empírico, mediante la implementación del MVP (variable independiente) en un entorno controlado y la medición de su impacto en la eficiencia del proceso de validación (variable dependiente). Se establecerán grupos de control (proceso tradicional) y experimental (usando el MVP) para medir indicadores como tiempo de generación, precisión y cobertura de los casos de prueba.

**Encuesta**: Se utilizará para obtener datos cuantificables sobre el proceso actual de identificación de casos de prueba y, posteriormente, sobre la experiencia de uso del MVP. Mediante cuestionarios estructurados aplicados a los miembros de los equipos ágiles, se recopilarán mediciones de variables como tiempos percibidos, satisfacción con la calidad de los casos generados y usabilidad de la herramienta.

**Análisis Documental**: Se realizará sobre artefactos como historias de usuario, especificaciones de requisitos, casos de prueba existentes y documentación de errores, para establecer métricas objetivas sobre la calidad y eficiencia del proceso actual. Este análisis proporcionará datos históricos sobre el rendimiento de la generación manual de casos de prueba que servirán como referencia comparativa.

**Análisis Estadístico**: Se aplicará para procesar los datos recopilados durante la experimentación, estableciendo comparaciones estadísticamente válidas entre los grupos de control y experimental. Mediante pruebas como t-Student, ANOVA u otras técnicas estadísticas apropiadas, se determinará si las diferencias observadas en eficiencia son estadísticamente significativas, validando así la hipótesis planteada.

La combinación de estos métodos teóricos y empíricos, coherentemente alineados con el enfoque cuantitativo y el diseño cuasi-experimental, garantizará una aproximación rigurosa y científica al objeto de estudio, facilitando tanto el desarrollo técnico del MVP como la validación empírica de su impacto en la eficiencia del proceso de validación de software en los equipos ágiles de Patito SRL.

## 2.6. Técnicas de Recolección de Datos de la Investigación

En consonancia con el enfoque cuantitativo y el diseño cuasi-experimental de la investigación, se aplicarán las siguientes técnicas de recolección de datos, seleccionadas para obtener información precisa y medible sobre las variables de estudio:

### 2.6.1. Técnicas de Observación Directa

Se aplicará la **observación sistemática estructurada** para registrar de manera objetiva el proceso actual de generación de casos de prueba en los Equipos Ágiles de Patito SRL. Esta técnica permitirá:

- Cronometrar tiempos de ejecución en cada fase del proceso de identificación de casos de prueba.
- Registrar mediante listas de verificación la completitud y exactitud de los casos generados.
- Documentar la interacción de los usuarios con las herramientas actuales y posteriormente con el MVP.
- Cuantificar la frecuencia de errores y reprocesos durante la actividad.

La observación se realizará utilizando protocolos estructurados con categorías predefinidas y escalas de medición, evitando así interpretaciones subjetivas y garantizando la replicabilidad de la técnica.

### 2.6.2. Técnicas de Encuesta

Se utilizará un **cuestionario estructurado** con preguntas cerradas y de escala Likert para:

- Medir la percepción de eficiencia del proceso actual por parte de los miembros del equipo.
- Cuantificar el esfuerzo percibido en la generación manual de casos de prueba.
- Evaluar el nivel de satisfacción con la calidad de los casos generados antes y después de implementar el MVP.
- Medir variables relacionadas con la usabilidad y aceptación del MVP implementado.

Estos cuestionarios se aplicarán en dos momentos: antes de la implementación del MVP (para establecer la línea base) y después de su implementación (para medir el impacto), tanto al grupo de control como al experimental.

### 2.6.3. Técnicas de Análisis Documental

Se empleará la **revisión documental estructurada** mediante:

- Matrices de registro para cuantificar características de los casos de prueba existentes (cobertura, efectividad en la detección de errores, etc.).
- Listas de verificación para evaluar la adherencia de los casos de prueba a estándares de calidad predefinidos.
- Formularios de extracción de datos para obtener métricas históricas de los proyectos de la empresa (tiempo de ciclo, tasas de defectos, etc.).

La documentación a analizar incluirá historias de usuario, especificaciones de requisitos, casos de prueba existentes, registros de errores y métricas de proyectos anteriores de Patito SRL.

### 2.6.4. Técnicas Experimentales

Se aplicarán **técnicas de experimentación controlada** mediante:

- Asignación de tareas específicas de generación de casos de prueba bajo condiciones controladas tanto al grupo experimental (utilizando el MVP) como al grupo de control (utilizando métodos tradicionales).
- Registro sistemático de variables dependientes como tiempo de ejecución, cobertura lograda y precisión de los casos generados.
- Control de variables extrañas que pudieran influir en los resultados (como la experiencia previa de los participantes o la complejidad de las tareas asignadas).

### 2.6.5. Técnicas de Medición

Se utilizarán **técnicas de medición cuantitativa** para evaluar el rendimiento del MVP y compararlo con los métodos tradicionales:

- Mediciones de tiempo mediante cronómetros y registros automatizados.
- Cálculos de porcentajes de cobertura utilizando herramientas especializadas.
- Conteo de errores detectados por los casos de prueba generados.
- Mediciones de esfuerzo (horas-persona) requeridas para completar las tareas.

Estas técnicas de recolección de datos están diseñadas para proporcionar información objetiva, cuantificable y verificable que permita evaluar rigurosamente la hipótesis planteada sobre la mejora en la eficiencia del proceso de validación de software mediante el MVP basado en IA. Los datos obtenidos serán procesados mediante técnicas estadísticas apropiadas para determinar la significancia de las diferencias observadas entre los grupos de control y experimental.

## 2.7. Instrumentos de Investigación

Los instrumentos de investigación han sido seleccionados y diseñados específicamente para garantizar la recolección de datos precisos, objetivos y cuantificables, en coherencia con el enfoque cuantitativo y el diseño cuasi-experimental del estudio. A continuación, se describen los instrumentos que se utilizarán:

### 2.7.1. Instrumentos para la Observación

**Ficha de Observación Estructurada**: Se diseñará una ficha con categorías predefinidas y escalas de medición para registrar el proceso de generación de casos de prueba. Este instrumento incluirá:
- Cronómetro digital para mediciones precisas de tiempo.
- Lista de verificación con indicadores observables específicos.
- Escalas de valoración numérica (1-5) para aspectos como la fluidez del proceso, dificultades encontradas y consultas realizadas.
- Tabla de registro de frecuencias para cuantificar eventos significativos durante el proceso.

**Registro Automatizado de Actividades**: Se implementará un software de monitoreo que registrará automáticamente:
- Tiempos dedicados a cada fase del proceso.
- Secuencia de acciones realizadas por los usuarios.
- Número de iteraciones o reprocesos en la generación de casos de prueba.
- Recursos computacionales utilizados (CPU, memoria, etc.).

### 2.7.2. Instrumentos para la Encuesta

**Cuestionario Pre-implementación del MVP**: Instrumento estructurado para establecer la línea base, con:
- Datos demográficos y perfil profesional de los participantes.
- Escala Likert (1-5) para medir percepciones sobre el proceso actual.
- Preguntas cerradas sobre tiempos estimados para completar tareas específicas.
- Preguntas de selección múltiple para identificar puntos críticos en el proceso.

**Cuestionario Post-implementación del MVP**: Similar al anterior pero enfocado en la experiencia con el MVP:
- Escala Likert (1-5) para medir la satisfacción con la herramienta.
- Comparativa directa entre el método tradicional y el MVP.
- Evaluación cuantitativa de la usabilidad mediante el System Usability Scale (SUS).
- Preguntas sobre la intención de uso futuro y recomendación.

### 2.7.3. Instrumentos para el Análisis Documental

**Matriz de Registro para Casos de Prueba**: Formato estructurado para codificar características relevantes:
- Identificación del caso (ID, fecha, autor).
- Métricas de calidad (completitud, claridad, trazabilidad).
- Métricas de eficacia (porcentaje de errores detectados, falsos positivos).
- Estadísticas de uso y mantenimiento.

**Formulario de Extracción de Datos Históricos**: Instrumento para sistematizar la recopilación de información histórica:
- Indicadores de rendimiento de proyectos anteriores.
- Métricas de calidad documentadas en ciclos previos.
- Datos sobre tiempos y recursos invertidos en testing.
- Indicadores de efectividad de las pruebas realizadas.

### 2.7.4. Instrumentos para la Experimentación Controlada

**Protocolo Experimental**: Documento detallado que especifica:
- Tareas estandarizadas que realizarán tanto el grupo control como el experimental.
- Variables a medir y técnicas de medición.
- Procedimientos para controlar variables extrañas.
- Cronograma y condiciones ambientales para los experimentos.

**Formulario de Registro de Resultados Experimentales**: Instrumento para documentar:
- Tiempos medidos en cada tarea asignada.
- Cobertura de requisitos lograda en los casos generados.
- Precisión y relevancia de los casos de prueba (evaluada por expertos).
- Observaciones específicas durante la sesión experimental.

### 2.7.5. Instrumentos para el Análisis de Datos

**Software de Análisis Estadístico**: Se utilizará un paquete estadístico profesional (como SPSS, R o similar) para:
- Cálculo de estadísticos descriptivos.
- Pruebas de hipótesis (t-Student, ANOVA).
- Análisis de correlación entre variables.
- Generación de visualizaciones y gráficos comparativos.

**Matriz de Operacionalización de Variables**: Instrumento que garantiza la correcta medición de las variables definidas:
- Definición operacional de cada variable.
- Indicadores específicos para cada dimensión.
- Escalas de medición aplicadas.
- Valores de referencia y umbrales para la interpretación.

Todos estos instrumentos serán validados antes de su aplicación mediante pruebas piloto y revisión por expertos para garantizar su confiabilidad y validez. Adicionalmente, se documentarán los procedimientos detallados para su aplicación, asegurando la estandarización del proceso de recolección de datos y la posibilidad de replicación futura del estudio.


## 2.8 Poblacion y muestra

La población de esta investigación está constituida por todos los profesionales que integran los equipos ágiles de Patito SRL, incluyendo ingenieros de software, testers, analistas de calidad, scrum masters y product owners que participan en los procesos de validación y testing de software en todas las sedes de la empresa. También forma parte de la población toda la infraestructura tecnológica que soporta estos procesos, incluyendo las herramientas actuales de gestión de pruebas, los repositorios de código, las plataformas de integración continua, los entornos de desarrollo y las bases de datos de casos de prueba históricos que constituyen el ecosistema donde se implementará el MVP basado en IA para la identificación eficiente de casos de prueba.

Para la implementación del enfoque cuantitativo con diseño cuasi-experimental, la muestra está constituida por una selección no probabilística e intencional de cuatro equipos ágiles completos de la sede principal de Patito SRL, dos asignados al grupo experimental (que utilizarán el MVP) y dos al grupo de control (que mantendrán las metodologías tradicionales). Esta selección incluye un total de 24 profesionales con diferentes roles y niveles de experiencia, así como 8 proyectos de desarrollo en curso con diferentes grados de complejidad y dominio de aplicación. Los equipos fueron seleccionados buscando maximizar la equivalencia inicial entre el grupo experimental y el de control en términos de experiencia previa, complejidad de los proyectos asignados y nivel de madurez en prácticas ágiles, para minimizar el efecto de variables extrañas.

La selección de la muestra responde a criterios de accesibilidad, representatividad de los diferentes roles y procesos de testing dentro de la organización, y factibilidad para la implementación controlada del MVP. Se han establecido criterios de inclusión que requieren que los participantes tengan al menos seis meses de experiencia en sus roles actuales y familiaridad con los procesos de validación de software de la empresa. Los proyectos seleccionados para la implementación experimental tienen características comparables en términos de tamaño (entre 100 y 150 historias de usuario), duración (ciclos de desarrollo de 3 meses) y dominio de negocio, lo que permitirá obtener resultados comparativos significativos sobre la eficiencia del MVP en contextos reales de desarrollo ágil dentro de Patito SRL.


# Referencias Bibliográficas

Aufiero Informática. (2023). *Generación automática de casos de prueba con IA*. [https://www.aufieroinformatica.com/generacion-de-casos-de-prueba-con-ia/](https://www.aufieroinformatica.com/generacion-de-casos-de-prueba-con-ia/) 

Baqar, M., & Khanda, R. (2024, Septiembre 9). *The future of software testing: AI-powered test case generation and validation* \[Preprint\]. arXiv. [https://doi.org/10.48550/arXiv.2409.05808](https://doi.org/10.48550/arXiv.2409.05808)

Certiprof. (2023). *La integración de la inteligencia artificial en metodologías ágiles*. [https://certiprof.com/es/blogs/news/la-integracion-de-la-inteligencia-artificial-en-el-agil](https://certiprof.com/es/blogs/news/la-integracion-de-la-inteligencia-artificial-en-el-agil)

Guru99. (2024). *Las 10 mejores herramientas de pruebas de IA para la automatización de pruebas de software*. [https://www.guru99.com/es/best-ai-testing-tools.html](https://www.guru99.com/es/best-ai-testing-tools.html)

Harman, M., & Clark, J. (2004). Metrics and methods for test data generation. *Journal of Systems and Software*, *73*(1), 65–81.

Khan, M., & Ali, F. (2023). *TestLab: An Intelligent Automated Software Testing Framework*. arXiv preprint arXiv:2306.03602. [https://arxiv.org/abs/2306.03602](https://arxiv.org/abs/2306.03602)

Li, Z., Harman, M., & Hierons, R. M. (2007). Search-based software testing for relational database applications. *Information and Software Technology*, *49*(4), 391–408.

Ramadan, A., Yasin, H., & Pektas, B. (2024, Septiembre 4). *The role of artificial intelligence and machine learning in software testing* \[Preprint\]. arXiv. [https://doi.org/10.48550/arXiv.2409.02693](https://doi.org/10.48550/arXiv.2409.02693)

Weyuker, E. J. (1998). Testing component-based software: A cautionary tale. *IEEE Software*, *15*(5), 52–59.

# Bibliografía

[in progress]

# Anexos

**Anexo 1.** Matriz FODA de situación actual en Patito SRL

|                                          | **Factores Internos**                                                                                                                                                                                                | **Factores Externos**                                                                                                                                                                                                            |
| :--------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Aspectos Positivos**                   | **FORTALEZAS (Strengths)**                                                                                                                                                                                           | **OPORTUNIDADES (Opportunities)**                                                                                                                                                                                                |
|                                          | - Existencia de equipos trabajando con metodologías ágiles.                                                                                                                                                          | - Adopción creciente de herramientas de Inteligencia Artificial en el sector del testing.                                                                                                                                       |
|                                          | - Iniciativas organizacionales previas o actuales enfocadas en mejorar la calidad del producto.                                                                                                                     | - Disponibilidad de tecnologías (bibliotecas, plataformas, frameworks) de IA y automatización compatibles con metodologías ágiles.                                                                                             |
|                                          | - (Potencial) Conocimiento interno sobre los procesos de desarrollo y testing actuales.                                                                                                                              | - Posibilidad de lograr un posicionamiento competitivo regional a través de la innovación tecnológica en QA.                                                                                                                   |
|                                          | - (Potencial) Cultura organizacional que podría estar abierta a la experimentación (MVP).                                                                                                                            | - Acceso a investigaciones y estudios recientes (como los citados) que validan los beneficios de la IA en testing.                                                                                                               |
| **Aspectos Negativos**                   | **DEBILIDADES (Weaknesses)**                                                                                                                                                                                         | **AMENAZAS (Threats)**                                                                                                                                                                                                           |
|                                          | - Dependencia significativa del esfuerzo humano y procesos manuales en la generación/identificación de casos de prueba.                                                                                              | - Alta competencia regional en el sector de desarrollo de software y soluciones tecnológicas.                                                                                                                                    |
|                                          | - Baja eficiencia operativa asociada a la falta de automatización avanzada en testing.                                                                                                                               | - Rápida evolución tecnológica que puede llevar a la obsolescencia de las herramientas o enfoques si no hay adaptación continua.                                                                                              |
|                                          | - (Potencial) Carencia de personal interno con experiencia o especialización en técnicas avanzadas de IA (ML/NLP) aplicadas a testing.                                                                                | - (Potencial) Curva de aprendizaje y costos asociados a la adopción e integración de nuevas tecnologías de IA.                                                                                                              |
|                                          | - (Potencial) Resistencia interna al cambio hacia nuevas metodologías o herramientas automatizadas.                                                                                                                   | - Cambios rápidos en los requisitos del mercado o de los clientes que exigen una adaptación constante de los procesos de testing.                                                                                                  |
|                                          | - Cobertura de pruebas actual posiblemente insuficiente y propensa a errores humanos.                                                                                                                                | - (Potencial) Dependencia de proveedores externos para ciertas herramientas o tecnologías de IA.                                                                                                                             |      
|                                          | - Posibles cuellos de botella en la fase de validación/testing que generan retrasos en las entregas.                                                                                                                |                                                                                                                                                                                                                                  |

**Fuente:** Análisis basado en la información contextual del proyecto, 2024. 